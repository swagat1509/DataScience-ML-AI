{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FocusEdumatics_Internship.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jSFb7rWuaB8"
      },
      "source": [
        "**Problem Statement**\n",
        "In this project we are trying to find:\n",
        "1. Which algorithm works best in Easy as well as Hard paragraphs regarding  Text  Summarisation.\n",
        "2. Create an input receiver that accepts the paragraph as input.\n",
        "3. When we provide a paragraph and a summary it will out put the similarity score comparing it with the summary produced by the algorithm.\n",
        "4. Analyse on different algorithms regarding the text summarizing capability alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xm0AW9YyD-F"
      },
      "source": [
        "Installing and Importing all the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6woou40OE4kD",
        "outputId": "7c5184b1-cf76-444c-af59-7fa699961b2a"
      },
      "source": [
        "pip install rouge"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgdyP48JHs9B"
      },
      "source": [
        "!pip install spacy\n",
        "!pip install transformers #==2.2.0\n",
        "!pip install neuralcoref\n",
        "\n",
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIQcAoHYHut1",
        "outputId": "e5c69ac6-f81f-47ac-e4a3-4284d8f24b84"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibLVARfOH7Ab",
        "outputId": "db1e7a0c-695e-4a15-ca39-77f81d8c72d3"
      },
      "source": [
        "pip install bert-extractive-summarizer "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (4.5.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.44)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (54.2.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->bert-extractive-summarizer) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->bert-extractive-summarizer) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGIDwlHPyjMd"
      },
      "source": [
        "**Task 1:** Here we have to find out that if we are inputting a summary of our own, then the system will compare the human summary and the algorithm generated summary and will produce the similarity between the two summaries.\n",
        "We will use the ROUGE score which takes into account the overlap of the words and gives the score.\n",
        "\n",
        "**Approach:** We will take in the human summary and the paragraph as inputs. We will then use the GPT-2 model to genertae the summary. Then we will compare the both by using the ROUGE score and will give the similarity measure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ8b4fxeJejE"
      },
      "source": [
        "def Calculate_Similarity_Score(summ,para):\n",
        "  from summarizer import TransformerSummarizer\n",
        "  GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\n",
        "  src_text = para\n",
        "  summerize = ''.join(GPT2_model(src_text, min_length=60, max_length=120))\n",
        "  from rouge import Rouge\n",
        "  hypothesis = summerize\n",
        "  reference = summ\n",
        "  rouge = Rouge()\n",
        "  scores = rouge.get_scores(hypothesis, reference)\n",
        "  print(scores[0]['rouge-1']['p'])\n",
        "  print(\"\\nThe similarity score in between the two summaries is {}\".format(scores[0]['rouge-1']['p']))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysi52k3_zfQj"
      },
      "source": [
        "**Exapmle Summary:** Municipal Corporation of Gurugram on Wednesday said that 19 out of 45 commercial building owners have decided to pay property tax instead of providing free parking to the public. Notably, MCG earlier offered a property tax waiver for building basements if they were used to provide free parking. However, the owners allegedly said that revenues from parking profited them more.\n",
        "\n",
        "**Example Paragraph:**Only 26 malls and commercial centres on Mehrauli-Gurgaon (MG) road, Golf Course Road and Sohna Road will offer free parking in their basements, the Municipal Corporation of Gurugram (MCG) announced on Wednesday.The MCG had earlier said it will waive property tax on basements if the same were used to provide free parking. Soon afterwards, 45 sites offered free parking but now some of the owners have agreed to pay the property tax instead of offering free parking service. As a result, the list has been trimmed to 26. Building owners said the revenue from parking is higher than the gains from the property tax waiver.The updated list is in the public domain on the civic body's website  www.mcg.gov.in. As reported earlier, MCG officials had reviewed the Central government's notification regarding evaluation of property tax for commercial spaces and that to led to the civic body announcing the clause of tax waiver in lieu of free parking space.The 26 establishments offering free parking are Suncity Business Tower, Paras Twin Towers, MGF The Palm Springs Plaza, Global Foyer, Vipul Tech Square, MPD Tower, Augusta Point, Paras Downtown Tower, Central Plaza and Centrum Plaza, all located on the Golf Course Road. On MG Road, ABW Tower, Sewa Corporate Park, Garden City Point, DLF Corporate Park, Platina Mall and Vipul Agora Mall will offer free parking. Unitech Cyber Park Sector 39, Unitech Business Zone and Nirvana Country Yard Sector 50 and Unitech Arcadia Sector 49 will also offer free parking.Omaxe City Centre, Omaxe Mall, Raheja Mall, ILD Trade Centre, Omaxe Celebration Mall and the Sapphire Mall on Sohna Road are also on the list.The MCG had the option of levying a property tax on the basements in commercial centres, but after reading the Central government guidelines, an option was given to building owners that if they did not levy a parking fee on customers, the property tax on basements will be waived. Hence, for the publics benefit, the MCG has placed free parking boards at these sites for their awareness, MCG Commissioner V Umashankar said.If the sites mentioned on the list are found levying a parking fee, the public can report complaints on the MCGs toll-free number  1800-180-1817  or email to support@mcg.gov.in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0t2NGUxTZfg",
        "outputId": "b769465d-ffcc-4585-d5cb-4ceace5df84a"
      },
      "source": [
        "inp = input(\"Do you want to input the paragraph or summary?\")\n",
        "\n",
        "if inp == \"summary\":\n",
        "  summ = input()\n",
        "  para = input(\"Please input the paragraph of which the above is the summary. Using our algorithm we will show how similary are the two summaries\")\n",
        "  Calculate_Similarity_Score(summ,para)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Do you want to input the paragraph or summary?summary\n",
            "Municipal Corporation of Gurugram on Wednesday said that 19 out of 45 commercial building owners have decided to pay property tax instead of providing free parking to the public. Notably, MCG earlier offered a property tax waiver for building basements if they were used to provide free parking. However, the owners allegedly said that revenues from parking profited them more.\n",
            "Please input the paragraph of which the above is the summary. Using our algorithm we will show how similary are the two summariesOnly 26 malls and commercial centres on Mehrauli-Gurgaon (MG) road, Golf Course Road and Sohna Road will offer free parking in their basements, the Municipal Corporation of Gurugram (MCG) announced on Wednesday.The MCG had earlier said it will waive property tax on basements if the same were used to provide free parking. Soon afterwards, 45 sites offered free parking but now some of the owners have agreed to pay the property tax instead of offering free parking service. As a result, the list has been trimmed to 26. Building owners said the revenue from parking is higher than the gains from the property tax waiver.The updated list is in the public domain on the civic body's website  www.mcg.gov.in. As reported earlier, MCG officials had reviewed the Central government's notification regarding evaluation of property tax for commercial spaces and that to led to the civic body announcing the clause of tax waiver in lieu of free parking space.The 26 establishments offering free parking are Suncity Business Tower, Paras Twin Towers, MGF The Palm Springs Plaza, Global Foyer, Vipul Tech Square, MPD Tower, Augusta Point, Paras Downtown Tower, Central Plaza and Centrum Plaza, all located on the Golf Course Road. On MG Road, ABW Tower, Sewa Corporate Park, Garden City Point, DLF Corporate Park, Platina Mall and Vipul Agora Mall will offer free parking. Unitech Cyber Park Sector 39, Unitech Business Zone and Nirvana Country Yard Sector 50 and Unitech Arcadia Sector 49 will also offer free parking.Omaxe City Centre, Omaxe Mall, Raheja Mall, ILD Trade Centre, Omaxe Celebration Mall and the Sapphire Mall on Sohna Road are also on the list.The MCG had the option of levying a property tax on the basements in commercial centres, but after reading the Central government guidelines, an option was given to building owners that if they did not levy a parking fee on customers, the property tax on basements will be waived. Hence, for the publics benefit, the MCG has placed free parking boards at these sites for their awareness, MCG Commissioner V Umashankar said.If the sites mentioned on the list are found levying a parking fee, the public can report complaints on the MCGs toll-free number  1800-180-1817  or email to support@mcg.gov.in.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7142857142857143\n",
            "\n",
            "The similarity score in between the two summaries is 0.7142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goqIwSSo0TbV"
      },
      "source": [
        "We can see above that the summary given and the summary generated are 71% similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK_GR19dXH5O"
      },
      "source": [
        "**Task 2:**  We will analyze the performance of different algorithms on the summarizatino task taking into account one hard and one easy paragraph. We will then compare the ROUGE scores to see the performance of the algorithms on each of them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psXPnajlgcPI"
      },
      "source": [
        "Below are the two paragraphs on which we will test the summarization. One is easy and one is hard paragraph. Along with that we have the Gold Standard summary which is the actual summary. We will compare the system generated summary against that by computing the ROUGE score. For simlicity we will take into account ROUGE-1 precision score only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm9p5AymT6r7"
      },
      "source": [
        "easy_paragraph = \"Only 26 malls and commercial centres on Mehrauli-Gurgaon (MG) road, Golf Course Road and Sohna Road will offer free parking in their basements, the Municipal Corporation of Gurugram (MCG) announced on Wednesday.The MCG had earlier said it will waive property tax on basements if the same were used to provide free parking. Soon afterwards, 45 sites offered free parking but now some of the owners have agreed to pay the property tax instead of offering free parking service. As a result, the list has been trimmed to 26. Building owners said the revenue from parking is higher than the gains from the property tax waiver. As reported earlier, MCG officials had reviewed the Central government's notification regarding evaluation of property tax for commercial spaces and that to led to the civic body announcing the clause of tax waiver in lieu of free parking space. The MCG had the option of levying a property tax on the basements in commercial centres, but after reading the Central government guidelines, an option was given to building owners that if they did not levy a parking fee on customers, the property tax on basements will be waived. Hence, for the publics benefit, the MCG has placed free parking boards at these sites for their awareness, MCG Commissioner V Umashankar said.If the sites mentioned on the list are found levying a parking fee, the public can report complaints on the MCGs toll-free number  1800-180-1817  or email to support@mcg.gov.in.\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcs8phmyWdYu"
      },
      "source": [
        "gold_standard_Summary_easy_paragraph = \"Municipal Corporation of Gurugram on Wednesday said that 19 out of 45 commercial building owners have decided to pay property tax instead of providing free parking to the public. Notably, MCG earlier offered a property tax waiver for building basements if they were used to provide free parking. However, the owners allegedly said that revenues from parking profited them more.\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tveEhlnVIe_"
      },
      "source": [
        "hard_paragraph = \"Tokyo, Dec 26 (PTI) Scientists in Japan have developed a new urine-powered sensor that can alert caregivers when a diaper is wet and ready to be changed. A team from the Ritsumeikan University in Japan worked on the diaper for about five years, with the aim of caring for ageing patients suffering from urinary incontinence. Producing a sensor suitable for a diaper proved to be a challenge, researchers said. They first developed a urine sensor too rigid to embed into a diaper. Flexible embeddable battery and sensor contain a chemical potentially unsafe for humans and their charging times varied. The new diaper sensors overcome all of those problems by using a urine-activated battery, Gizmodo reported. \" "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpBAWyE8Wnni"
      },
      "source": [
        "gold_standard_Summary_hard_paragraph = \"Japanese scientists have developed a urine-powered sensor that can alert caregivers when a diaper is wet. It took the scientists five years to develop a flexible embeddable battery and urine sensor for diaper. The setup contains a battery attached to capacitor that stores generated electricity and a transmitter which can beam signal to a receiver up to 16 feet away.\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-aFnH8HXA3w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAQe94nIXrBs"
      },
      "source": [
        "**T5-Small**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-6XfLf00wjk"
      },
      "source": [
        "Summarization for the hard paragraph using the T5 Small algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQWxt_VC3kuG"
      },
      "source": [
        "import torch\n",
        "import json \n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBACZ28ufXt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51bd7b7e-3caa-4de4-8583-84ff72cb1cd7"
      },
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "device = torch.device('cpu')\n",
        "\n",
        "text = hard_paragraph\n",
        "\n",
        "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
        "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
        "print (\"original text preprocessed: \\n\", preprocess_text)\n",
        "\n",
        "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "\n",
        "# summmarize \n",
        "summary_ids = model.generate(tokenized_text,\n",
        "                                    num_beams=4,\n",
        "                                    no_repeat_ngram_size=2,\n",
        "                                    min_length=30,\n",
        "                                    max_length=512,\n",
        "                                    early_stopping=True)\n",
        "\n",
        "output_hard = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print (\"\\n\\nSummarized text: \\n\",output_hard)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original text preprocessed: \n",
            " Tokyo, Dec 26 (PTI) Scientists in Japan have developed a new urine-powered sensor that can alert caregivers when a diaper is wet and ready to be changed. A team from the Ritsumeikan University in Japan worked on the diaper for about five years, with the aim of caring for ageing patients suffering from urinary incontinence. Producing a sensor suitable for a diaper proved to be a challenge, researchers said. They first developed a urine sensor too rigid to embed into a diaper. Flexible embeddable battery and sensor contain a chemical potentially unsafe for humans and their charging times varied. The new diaper sensors overcome all of those problems by using a urine-activated battery, Gizmodo reported.\n",
            "\n",
            "\n",
            "Summarized text: \n",
            " the urine-powered sensor can alert caregivers when a diaper is wet and ready to be changed. the sensor was developed by the Ritsumeikan university in japan for about five years, with the aim of caring for ageing patients suffering from urinary incontinence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQMywp4-09QJ"
      },
      "source": [
        "Calculation of the ROUGE score for the hard text summary with the Gold Standard summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K13qqIRoWA1A",
        "outputId": "64587158-24da-43aa-bdb0-8d6f1a532310"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = output_hard\n",
        "reference = gold_standard_Summary_hard_paragraph\n",
        "rouge = Rouge()\n",
        "scores_hard_t5 = rouge.get_scores(hypothesis, reference)\n",
        "scores_hard_t5"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.33333332848904274,\n",
              "   'p': 0.40476190476190477,\n",
              "   'r': 0.2833333333333333},\n",
              "  'rouge-2': {'f': 0.15999999516200014,\n",
              "   'p': 0.1951219512195122,\n",
              "   'r': 0.13559322033898305},\n",
              "  'rouge-l': {'f': 0.31707316577929806,\n",
              "   'p': 0.35135135135135137,\n",
              "   'r': 0.28888888888888886}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qiwoczvg1NQ-"
      },
      "source": [
        "Summarization for the Easy text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnivSY3Eiqkw",
        "outputId": "ae5de34a-d5ab-4eec-e439-a00aa6354609"
      },
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "device = torch.device('cpu')\n",
        "\n",
        "text = easy_paragraph\n",
        "\n",
        "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
        "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
        "print (\"original text preprocessed: \\n\", preprocess_text)\n",
        "\n",
        "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "\n",
        "# summmarize \n",
        "summary_ids = model.generate(tokenized_text,\n",
        "                                    num_beams=4,\n",
        "                                    no_repeat_ngram_size=2,\n",
        "                                    min_length=30,\n",
        "                                    max_length=512,\n",
        "                                    early_stopping=True)\n",
        "\n",
        "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print (\"\\n\\nSummarized text: \\n\",output)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original text preprocessed: \n",
            " Only 26 malls and commercial centres on Mehrauli-Gurgaon (MG) road, Golf Course Road and Sohna Road will offer free parking in their basements, the Municipal Corporation of Gurugram (MCG) announced on Wednesday.The MCG had earlier said it will waive property tax on basements if the same were used to provide free parking. Soon afterwards, 45 sites offered free parking but now some of the owners have agreed to pay the property tax instead of offering free parking service. As a result, the list has been trimmed to 26. Building owners said the revenue from parking is higher than the gains from the property tax waiver. As reported earlier, MCG officials had reviewed the Central government's notification regarding evaluation of property tax for commercial spaces and that to led to the civic body announcing the clause of tax waiver in lieu of free parking space. The MCG had the option of levying a property tax on the basements in commercial centres, but after reading the Central government guidelines, an option was given to building owners that if they did not levy a parking fee on customers, the property tax on basements will be waived. Hence, for the publics benefit, the MCG has placed free parking boards at these sites for their awareness, MCG Commissioner V Umashankar said.If the sites mentioned on the list are found levying a parking fee, the public can report complaints on the MCGs toll-free number  1800-180-1817  or email to support@mcg.gov.in.\n",
            "\n",
            "\n",
            "Summarized text: \n",
            " only 26 malls and commercial centres on Mehrauli-Gurgaon (MG) road, Golf Course Road and Sohna Road will offer free parking in their basements. building owners said the revenue from parking is higher than the gains from the property tax waiver, which led to the announcement of a clause of tax waive in lieu of parking space. the public can report complaints on the MCGs toll-free number 1800-180-1817 or email to support@mcg.gov.in.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShBBPSGQ1UXH"
      },
      "source": [
        "ROUGE score calculation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFCPL1fyjWMN",
        "outputId": "11bdc074-8467-4cc6-8ced-ee9ba435eedf"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = output\n",
        "reference = gold_standard_Summary_easy_paragraph\n",
        "rouge = Rouge()\n",
        "scores_easy_t5 = rouge.get_scores(hypothesis, reference)\n",
        "scores_easy_t5"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.3458646567019052,\n",
              "   'p': 0.3150684931506849,\n",
              "   'r': 0.38333333333333336},\n",
              "  'rouge-2': {'f': 0.09160304848435434,\n",
              "   'p': 0.08333333333333333,\n",
              "   'r': 0.1016949152542373},\n",
              "  'rouge-l': {'f': 0.23529411269511738,\n",
              "   'p': 0.21428571428571427,\n",
              "   'r': 0.2608695652173913}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsdHdYYzkWET"
      },
      "source": [
        "**PEGASUS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AQkNGWCf7AN"
      },
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoUpjcBFYO8h",
        "outputId": "aee614a0-2e45-4ee4-8816-24966933652e"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAYfPz5hkJAj"
      },
      "source": [
        "Summarization for the hard sentence and calculating the ROUGE score using Pegasus "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAbQPSKJniw0"
      },
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch\n",
        "src_text = [hard_paragraph]\n",
        "\n",
        "model_name = 'google/pegasus-xsum'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#device = 'gpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
        "translated = model.generate(**batch)\n",
        "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "tgt_text = \" \".join(tgt_text)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc2Khmf5kuVB",
        "outputId": "38a38827-9623-401e-b522-464875ad8b0d"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = tgt_text\n",
        "reference = gold_standard_Summary_hard_paragraph\n",
        "rouge = Rouge()\n",
        "scores_hard_pegasus = rouge.get_scores(hypothesis, reference)\n",
        "scores_hard_pegasus"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.39506172455418387,\n",
              "   'p': 0.7619047619047619,\n",
              "   'r': 0.26666666666666666},\n",
              "  'rouge-2': {'f': 0.3037974645729851, 'p': 0.6, 'r': 0.2033898305084746},\n",
              "  'rouge-l': {'f': 0.4307692265088758, 'p': 0.7, 'r': 0.3111111111111111}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Sgle212Ao1"
      },
      "source": [
        "Summarization for the easy sentence and calculating the ROUGE score using Pegasus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN7-A7Elne0n"
      },
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch\n",
        "src_text = [easy_paragraph]\n",
        "\n",
        "model_name = 'google/pegasus-xsum'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#device = 'gpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
        "translated = model.generate(**batch)\n",
        "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "tgt_text = \" \".join(tgt_text)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8VjkOUlne23",
        "outputId": "26df1704-6de2-4adc-8234-2a448fc22d21"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = tgt_text\n",
        "reference = gold_standard_Summary_easy_paragraph\n",
        "rouge = Rouge()\n",
        "scores_easy_pegasus = rouge.get_scores(hypothesis, reference)\n",
        "scores_easy_pegasus"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.21739129981096417, 'p': 0.3125, 'r': 0.16666666666666666},\n",
              "  'rouge-2': {'f': 0.1111111065950619,\n",
              "   'p': 0.16129032258064516,\n",
              "   'r': 0.0847457627118644},\n",
              "  'rouge-l': {'f': 0.21333332859022233,\n",
              "   'p': 0.27586206896551724,\n",
              "   'r': 0.17391304347826086}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-Cvia-j2gQD"
      },
      "source": [
        "Summarization for the hard sentence and calculating the ROUGE score using GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyzbDMa_DKfL",
        "outputId": "a1ec9135-b892-4c43-b431-f79557d35672"
      },
      "source": [
        "from summarizer import TransformerSummarizer\n",
        "GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\n",
        "src_text = hard_paragraph\n",
        "summerize_hard = ''.join(GPT2_model(src_text, min_length=60, max_length=120))\n",
        "print(summerize_hard)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Producing a sensor suitable for a diaper proved to be a challenge, researchers said.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jffJXNTGpoXh",
        "outputId": "b371d46a-48b1-4afb-ea5a-93e4d142d291"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = summerize_hard\n",
        "reference = gold_standard_Summary_hard_paragraph\n",
        "rouge = Rouge()\n",
        "scores_hard_gpt2 = rouge.get_scores(hypothesis, reference)\n",
        "scores_hard_gpt2"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.18918918612125643, 'p': 0.5, 'r': 0.11666666666666667},\n",
              "  'rouge-2': {'f': 0.027777774818673155,\n",
              "   'p': 0.07692307692307693,\n",
              "   'r': 0.01694915254237288},\n",
              "  'rouge-l': {'f': 0.17543859316712837,\n",
              "   'p': 0.4166666666666667,\n",
              "   'r': 0.1111111111111111}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1VTQ5RO3I1o"
      },
      "source": [
        "Summarization for the easy sentence and calculating the ROUGE score using GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3doex3rp55Q",
        "outputId": "33009a98-e015-4894-9c9c-bc57ae107f7e"
      },
      "source": [
        "from summarizer import TransformerSummarizer\n",
        "GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\n",
        "src_text = easy_paragraph\n",
        "summerize_easy = ''.join(GPT2_model(src_text, min_length=60, max_length=120))\n",
        "print(summerize_easy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The MCG had earlier said it will waive property tax on basements if the same were used to provide free parking.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkg4-FEyp58b",
        "outputId": "ebe53d39-4a59-49e9-9f1a-83934ac22ae1"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = summerize_easy\n",
        "reference = gold_standard_Summary_easy_paragraph\n",
        "rouge = Rouge()\n",
        "scores_easy_gpt2 = rouge.get_scores(hypothesis, reference)\n",
        "scores_easy_gpt2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.37037036652949246, 'p': 0.7142857142857143, 'r': 0.25},\n",
              "  'rouge-2': {'f': 0.1772151860919725, 'p': 0.35, 'r': 0.11864406779661017},\n",
              "  'rouge-l': {'f': 0.3880596971886835,\n",
              "   'p': 0.6190476190476191,\n",
              "   'r': 0.2826086956521739}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xt4BkUN3ge3"
      },
      "source": [
        "Summarization for the hard sentence and calculating the ROUGE score using XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngbqe-9yGyPx",
        "outputId": "4711b3ec-9462-4d5a-cad4-115d6e53dc8a"
      },
      "source": [
        "from summarizer import TransformerSummarizer\n",
        "xlnet_model = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
        "src_text_XLNet = hard_paragraph\n",
        "summerize_XLnet_hard = ''.join(xlnet_model(src_text_XLNet, min_length=60, max_length=120))\n",
        "print(summerize_XLnet_hard)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Producing a sensor suitable for a diaper proved to be a challenge, researchers said.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUT4biD7qrzM",
        "outputId": "eaf5ced9-af54-4462-8ca8-8c2305324652"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = summerize_XLnet_hard\n",
        "reference = gold_standard_Summary_hard_paragraph\n",
        "rouge = Rouge()\n",
        "scores_hard_XLNet = rouge.get_scores(hypothesis, reference)\n",
        "scores_hard_XLNet"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.18918918612125643, 'p': 0.5, 'r': 0.11666666666666667},\n",
              "  'rouge-2': {'f': 0.027777774818673155,\n",
              "   'p': 0.07692307692307693,\n",
              "   'r': 0.01694915254237288},\n",
              "  'rouge-l': {'f': 0.17543859316712837,\n",
              "   'p': 0.4166666666666667,\n",
              "   'r': 0.1111111111111111}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGndYto8k8hM",
        "outputId": "7fbff51f-37aa-445e-d43c-af8c1ecafed7"
      },
      "source": [
        "from summarizer import TransformerSummarizer\n",
        "xlnet_model = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
        "src_text_XLNet_e = easy_paragraph\n",
        "summerize_XLnet_easy = ''.join(xlnet_model(src_text_XLNet_e, min_length=60, max_length=120))\n",
        "print(summerize_XLnet_easy)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MCG had earlier said it will waive property tax on basements if the same were used to provide free parking. Building owners said the revenue from parking is higher than the gains from the property tax waiver.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmspNZ7zrOAz",
        "outputId": "5aabe722-1381-49b9-d6a7-7286c2027c24"
      },
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = summerize_XLnet_easy\n",
        "reference = gold_standard_Summary_easy_paragraph\n",
        "rouge = Rouge()\n",
        "scores_easy_XLNet = rouge.get_scores(hypothesis, reference)\n",
        "scores_easy_XLNet"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.46938775035401914,\n",
              "   'p': 0.6052631578947368,\n",
              "   'r': 0.38333333333333336},\n",
              "  'rouge-2': {'f': 0.20833332859592024,\n",
              "   'p': 0.2702702702702703,\n",
              "   'r': 0.1694915254237288},\n",
              "  'rouge-l': {'f': 0.44736841627423823,\n",
              "   'p': 0.5666666666666667,\n",
              "   'r': 0.3695652173913043}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0anrSvAs_oP"
      },
      "source": [
        "Now we will compare the ROUGE-1 perscision score of all the algoritms to see in which both the easy and the hard paragraphs were summarized equally efficiently among all the algos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyyA9LbOtWW9",
        "outputId": "7361cef9-af02-4e57-a0c3-078eccac7243"
      },
      "source": [
        "print(\"\\nFor the T5 the ROUGE-1 percision score for the HARD paragraph is  {}\".format(scores_hard_t5[0]['rouge-1']['p']))\n",
        "print(\"\\nFor the T5 the ROUGE-1 percision score for the EASY paragraph is  {}\".format(scores_easy_t5[0]['rouge-1']['p']))\n",
        "print(\"\\nFor the PEGASUS the ROUGE-1 percision score for the HARD paragraph is  {}\".format(scores_hard_pegasus[0]['rouge-1']['p']))\n",
        "print(\"\\nFor the PEGASUS the ROUGE-1 percision score for the EASY paragraph is  {}\".format(scores_easy_pegasus[0]['rouge-1']['p']))\n",
        "print(\"\\nFor the GPT-2 the ROUGE-1 percision score for the HARD paragraph is  {}\".format(scores_hard_gpt2[0]['rouge-1']['p']))\n",
        "print(\"\\nFor the GPT-2 the ROUGE-1 percision score for the EASY paragraph is  {}\".format(scores_easy_gpt2[0]['rouge-1']['p']))\n",
        "print(\"\\nFor the XLNet the ROUGE-1 percision score for the HARD paragraph is  {}\".format(scores_hard_XLNet[0]['rouge-1']['p']))\n",
        "print(\"\\nFor the XLNet the ROUGE-1 percision score for the EASY paragraph is  {}\".format(scores_easy_XLNet[0]['rouge-1']['p']))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For the T5 the ROUGE-1 percision score for the HARD paragraph is  0.40476190476190477\n",
            "\n",
            "For the T5 the ROUGE-1 percision score for the EASY paragraph is  0.3150684931506849\n",
            "\n",
            "For the PEGASUS the ROUGE-1 percision score for the HARD paragraph is  0.7619047619047619\n",
            "\n",
            "For the PEGASUS the ROUGE-1 percision score for the EASY paragraph is  0.3125\n",
            "\n",
            "For the GPT-2 the ROUGE-1 percision score for the HARD paragraph is  0.5\n",
            "\n",
            "For the GPT-2 the ROUGE-1 percision score for the EASY paragraph is  0.7142857142857143\n",
            "\n",
            "For the XLNet the ROUGE-1 percision score for the HARD paragraph is  0.5\n",
            "\n",
            "For the XLNet the ROUGE-1 percision score for the EASY paragraph is  0.6052631578947368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TQ5fS6t5EiF"
      },
      "source": [
        "So from the above scores we can see that XLNet has summarized the easy and hard texts almost equally fairly with ROUGE scores being the most close."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxwpiX6DuHwb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}